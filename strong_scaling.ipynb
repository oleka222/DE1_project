{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28b9d5-833b-436e-bb28-3243f32102db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction as UDF\n",
    "from pyspark.sql.functions import size, col\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "import time\n",
    "    \n",
    "def do_one_round(spark_executor_cores = 4, spark_cores_max = 16):\n",
    "    start_time = time.time()\n",
    "    print(f\"RUNNING with spark_executor_cores = {spark_executor_cores}; spark_cores_max = {spark_cores_max}\")\n",
    "    '''\n",
    "    spark.executor.cores - The number of cores to use on each executor (worker)\n",
    "\n",
    "    spark.cores.max - the maximum amount of CPU cores to request for the application \n",
    "                      from across the cluster (not from each machine).\n",
    "    '''\n",
    "\n",
    "    ss = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"spark://192.168.2.61:7077\") \\\n",
    "            .appName(\"irina_strong_scaling\")\\\n",
    "            .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "            .config(\"spark.executor.cores\",spark_executor_cores)\\\n",
    "            .config(\"spark.cores.max\",spark_cores_max)\\\n",
    "            .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "            .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "            .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\")\\\n",
    "            .config(\"spark.driver.port\", 9998)\\\n",
    "            .config(\"spark.blockManager.port\", 10005)\\\n",
    "            .getOrCreate()  # Read file\n",
    "    start_time = time.time()\n",
    "    df = ss.read.json('hdfs://192.168.2.184:9000/RC_2009-09')\n",
    "    df.printSchema()\n",
    "\n",
    "    # Drop unused columns\n",
    "    df = df.drop('archived', 'author', 'author_flair_css_class', 'author_flair_text', 'created_utc', 'edited',            'gilded', 'id', 'link_id', 'name', 'parent_id', 'removal_reason', 'retrieved_on',            'score_hidden', 'subreddit_id', 'distinguished', 'controversiality');\n",
    "    df.printSchema()\n",
    "\n",
    "    # Tokenize comment body\n",
    "    import string\n",
    "    def tokenize(text):\n",
    "        return text.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "\n",
    "    udf_tokenize =  UDF(tokenize, ArrayType(StringType()))\n",
    "    df = df.withColumn('body', udf_tokenize(df.body))\n",
    "\n",
    "    # Comment length feature\n",
    "    df = df.withColumn('comment_length', size(df.body))\n",
    "\n",
    "    # Deleted comment feature\n",
    "    def check_deleted(line):\n",
    "        if line == ['removed'] or line == ['deleted']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    udf_deleted = UDF(check_deleted, IntegerType())\n",
    "    df = df.withColumn('deleted', udf_deleted(df.body))\n",
    "\n",
    "    df.select('deleted').show()\n",
    "\n",
    "    # Controversial words feature\n",
    "    cont_words = 'abuse, administration, afghanistan, aid, america,' + 'american, army, attack, attacks, authorities, authority, ban, banks, benefits, bill, bills,' + 'border, budget, campaign, candidate, candidates, catholic, china, chinese, church,'+ 'concerns, congress, conservative, control, country, court, crime, criminal, crisis, cuts,'+'debate, debt, defense, deficit, democrats, disease, dollar, drug, drugs, economy, education,'+'egypt, election, elections, enforcement, fighting, finance, fiscal, force, funding,'+'gas, government, gun, health, immigration, inaccuracies, india, insurance, investigation,'+'investigators, iran, israel, job, jobs, judge, justice, killing, korea, labor, land,'+'law, lawmakers, laws, lawsuit, leadership, legislation, marriage, media, mexico, military,'+'money, murder, nation, nations, news, obama, offensive, officials, oil, parties,'+'peace, police, policies, policy, politics, poll, power, president, prices, primary, prison,'+'progress, race, reform, republican, republicans, restrictions, rule, rules, ruling, russia,'+'russian, school, security, senate, sex, shooting, society, spending, strategy, strike, support,'+'syria, syrian, tax, taxes, threat, trial, unemployment, union, usa, victim, victims,'+'violence, vote, voters, war, washington, weapons, world,'\n",
    "    semi_cont_words = 'account, advantage, amount, attorney, chairman,'+'charge, charges, cities, class, comment, companies, cost, credit, delays, effect, expectations,'+'families, family, february, germany, goal, housing, information, investment,'+'markets, numbers, oklahoma, parents, patients, population, price, projects, raise, rate,'+'reason, sales, schools, sector, shot, source, sources, status, stock, store, worth,'\n",
    "\n",
    "    controversial = tokenize(cont_words)\n",
    "    semi_controversial = tokenize(semi_cont_words)\n",
    "\n",
    "    def controversial_words(line, controversial = controversial, semi_controversial = semi_controversial):\n",
    "        score = 0\n",
    "        for word in line:\n",
    "            if word in controversial:\n",
    "                score += 3\n",
    "            elif word in semi_controversial:\n",
    "                score += 1\n",
    "        return score\n",
    "        \n",
    "    udf_controversial = UDF(controversial_words, IntegerType())\n",
    "    df = df.withColumn('cont_word_score', udf_controversial('body'))\n",
    "    df.select('subreddit').show()\n",
    "\n",
    "    df.printSchema()\n",
    "\n",
    "    controversial_subreddits = [\"Conservative\", \"syriancivilwar\", \"conspiracy\", \"SeattleWA\", \"ukpolitics\", \"canada\", \"DC_cinematics\", \"worldnews\", \"bestof\", \"news\", \"europe\", \"Austin\", \"Documentaries\", \"PublicFreakout\", \"Portland\", \"JusticeServed\", \"JoeRogan\", \"toronto\", \"Games\", \"vancouver\"] \n",
    "\n",
    "    #check if comment was posted on potentially controversial subreddit\n",
    "    def controversial_subreddits(line, controversial_subreddits = controversial_subreddits):\n",
    "        if line in controversial_subreddits:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    udf_subreddits = UDF(controversial_subreddits, IntegerType())   \n",
    "    df = df.withColumn('cont_subreddits', udf_controversial(df.subreddit))\n",
    "\n",
    "    #dropping columns we develop features on, just in case changing long ints to ints\n",
    "    df = df.drop(\"subreddit\", \"body\")\n",
    "    df = df.withColumn('downs',df['downs'].cast(\"int\").alias('downs'))\n",
    "    df = df.withColumn('ups',df['ups'].cast(\"int\").alias('ups'))\n",
    "    df = df.withColumn('score',df['score'].cast(\"int\").alias('score'))\n",
    "\n",
    "    df.printSchema()\n",
    "\n",
    "    #calculatiog ratio postive class/negative class\n",
    "    positive = df.filter(col(\"deleted\") == 1)\n",
    "    negative = df.filter(col(\"deleted\") == 0)\n",
    "    ratio = positive.count()/negative.count()\n",
    "    print(\"ratio: {}\".format(ratio))\n",
    "\n",
    "    #undersampling\n",
    "    sampled_df = negative.sample(False, ratio)\n",
    "    undersampled_df = sampled_df.unionAll(positive)\n",
    "\n",
    "    #checking if undersampling worked\n",
    "    undersampled_df.select(\"deleted\").where(undersampled_df[\"deleted\"] == 1).count()\n",
    "\n",
    "    #checking if undersampling worked\n",
    "    undersampled_df.select(\"deleted\").where(undersampled_df[\"deleted\"] == 0).count()\n",
    "    undersampled_df.show()\n",
    "\n",
    "    from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "    #score, ups and downs are correlated but they may work differently with different version of reddit comments\n",
    "    #putting features into vector of features\n",
    "    numericCols = ['ups', 'downs', 'score', 'cont_word_score','cont_subreddits']\n",
    "    assemblerInputs =  numericCols\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    stages = [assembler]\n",
    "\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    from pyspark.ml import Pipeline\n",
    "    #making column of feature vectots\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    pipelineModel = pipeline.fit(undersampled_df)\n",
    "    model_df = pipelineModel.transform(undersampled_df)\n",
    "\n",
    "    #checking if it worked\n",
    "    model_df.select(\"features\").show()\n",
    "\n",
    "    #triai-test split\n",
    "    train, test = model_df.randomSplit([0.8, 0.2], seed = 3)\n",
    "\n",
    "    #training logistic regression\n",
    "    reg_time = time.time()\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    lr = LogisticRegression(featuresCol = 'features', labelCol = 'deleted', maxIter=10)\n",
    "    lrModel = lr.fit(train)\n",
    "\n",
    "    #checking if better than random classifier\n",
    "    trainingSummary = lrModel.summary\n",
    "    roc = trainingSummary.roc.toPandas()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(roc['FPR'],roc['TPR'])\n",
    "    plt.ylabel('False Positive Rate')\n",
    "    plt.xlabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()\n",
    "    print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "    #making predictions on test dataset\n",
    "    predictions = lrModel.transform(test)\n",
    "\n",
    "    #calculating accuracy\n",
    "    accuracy = predictions.filter(predictions.deleted == predictions.prediction).count() / float(predictions.count())\n",
    "    total_reg = time.time() - reg_time   \n",
    "    \n",
    "    accuracy\n",
    "\n",
    "    #checking which \n",
    "    lrModel.coefficients\n",
    "\n",
    "    ss.sparkContext.stop()\n",
    "    ss.stop()\n",
    "    total_exec = time.time() - start_time\n",
    "    print(f\"SETUP:\\nspark_executor_cores = {spark_executor_cores}\\nspark_cores_max = {spark_cores_max}\")\n",
    "    print(f\"LOG_REG execution time: {total_reg}\")    \n",
    "    print(f\"TOTAL execution time: {total_exec}\")\n",
    "    \n",
    "    return [spark_cores_max, spark_executor_cores, total_reg, total_exec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145dfaa-9863-4338-be4b-c6cd68963361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_one_round(spark_executor_cores = 4, spark_cores_max = 16):\n",
    "#spark_executor_cores - max cores on each worker       \n",
    "#spark_cores_max - max cores on the whole cluster\n",
    "\n",
    "num_cores_config = [1, 2, 4, 8, 12, 16]\n",
    "n_iters = 3\n",
    "\n",
    "results  = []\n",
    "for c in num_cores_config:\n",
    "    for i in range(0, n_iters):\n",
    "        print(f\"START COMPUTE WITH CORES NUM {c}\")\n",
    "        spark_executor_cores = 4 if c > 4 else c\n",
    "        t = do_one_round(spark_cores_max = c, spark_executor_cores = spark_executor_cores)\n",
    "        print(f\"RESULT: {t}\")\n",
    "        results.append([t])\n",
    "print(\"FORMAT: [spark_cores_max, spark_executor_cores, total_reg, total_exec]\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451ba8a-bfd4-409c-8f7a-dd260c29e962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
